{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nuTdRhYb4WLo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwm6WcOu6Wb2",
        "outputId": "8fb4e1df-e321-4a52-e196-0982a7c21cb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/ML-Transportation-Rate/Raw_Data_Past_Four_Month\"\n",
        "MT_data_ori = pd.read_csv(path +'/Merged_DataFrame_hash_Version_addition.csv')\n",
        "DAT_data = pd.read_excel(path +'/DAT_Rates_from_DB-9-21.xlsx')"
      ],
      "metadata": {
        "id": "hvtl5Q346aan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f875b2f-da39-4d51-c2af-87fe3008cf64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (12,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MT_data = MT_data_ori.sample(1000000)\n",
        "\n",
        "# Create a column called ID_OR_OPTIONAL_FIELD, which join first three letter of ORIGIN zip\n",
        "# and the first three letter of DEST zip and connect them by using \"_\"\n",
        "MT_data['ID_OR_OPTIONAL_FIELD'] = MT_data['ORIGIN ZIP'].astype(str).str[:3] + '_' + MT_data['DEST ZIP'].astype(str).str[:3] \n",
        "MT_data['ID_OR_OPTIONAL_FIELD'] = MT_data['ID_OR_OPTIONAL_FIELD'].astype(str)\n",
        "\n",
        "\n",
        "#Remove Columns of 'Unnamed: 0.1','Unnamed: 0'\n",
        "MT_data = MT_data.drop(['Unnamed: 0.1','Unnamed: 0'], axis = 1)\n",
        "\n",
        "# Drop the row if na is found in the MT_data['DISTANCE']\n",
        "MT_data = MT_data[pd.notnull(MT_data['DISTANCE'])]\n",
        "\n",
        "# Drop the row if na is found in the MT_data['WEIGHT]\n",
        "MT_data = MT_data[pd.notnull(MT_data['WEIGHT'])]\n",
        "\n",
        "# Drop the row if na is found in the MT_data['VOLUME']\n",
        "MT_data = MT_data[pd.notnull(MT_data['VOLUME'])]\n",
        "\n",
        "\n",
        "# Drop the row if na is found in the MT_data['ORIGIN CITY']\n",
        "MT_data = MT_data[pd.notnull(MT_data['ORIGIN CITY'])]\n",
        "\n",
        "# Only conisder shipment has Original zip code in USA and Canada\n",
        "# Drop the row if ns is found in the MT_data['ORIGIN STATE']\n",
        "MT_data = MT_data[pd.notnull(MT_data['ORIGIN STATE'])]\n",
        "MT_data = MT_data.reset_index(drop=True)\n",
        "\n",
        "US_list = [ 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
        "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
        "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
        "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
        "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
        "Canada_list = ['AB','BC','MB','NB','NL','NT','NS','NU','ON','PE','QC','SK','YT']\n",
        "State_list = US_list + Canada_list\n",
        "\n",
        "for i in range(len(MT_data)):\n",
        "    if MT_data.loc[i,'ORIGIN STATE'] in State_list:\n",
        "        pass\n",
        "    else:\n",
        "        MT_data = MT_data.drop(i)\n",
        "        \n",
        "        \n",
        "# Drop the row if na is found in the MT_data['ORIGIN ZIP']\n",
        "MT_data = MT_data[pd.notnull(MT_data['ORIGIN ZIP'])]\n",
        "MT_data = MT_data.reset_index(drop=True)\n",
        "# Change 4 digits zips to 5 digis\n",
        "for i in (range(len(MT_data['ORIGIN ZIP']))):\n",
        "    zipCode = str(MT_data.loc[i,'ORIGIN ZIP'])\n",
        "    if zipCode.isdigit():\n",
        "        if len(zipCode) < 5:\n",
        "            MT_data.loc[i,'ORIGIN ZIP'] = \"0\" * (5 - len(zipCode)) + zipCode\n",
        "    else:\n",
        "        pass\n",
        "            \n",
        "\n",
        "\n",
        "# Actual mode will only consider LTL, and TL\n",
        "# Drop the row if ns is found in the MT_data['ACTUAL MODE']\n",
        "MT_data = MT_data[pd.notnull(MT_data['ACTUAL MODE'])]\n",
        "MT_data['ACTUAL MODE'] = MT_data['ACTUAL MODE'].str.split('.').str[-1] \n",
        "MT_data['ACTUAL MODE'] = MT_data['ACTUAL MODE'].str.upper()\n",
        "MT_data = MT_data.reset_index(drop=True)\n",
        "\n",
        "acutual_mode_list = ['LTL','TL','INTERMODAL']\n",
        "\n",
        "for i in range(len(MT_data)):\n",
        "    if MT_data.loc[i,'ACTUAL MODE'] in acutual_mode_list:\n",
        "        pass\n",
        "    else:\n",
        "      MT_data = MT_data.drop(i)\n",
        "        \n",
        "# Remove any nan cell in ACTUAL EQUIP\n",
        "# Tokenize part information from the original cells\n",
        "MT_data = MT_data[pd.notnull(MT_data['ACTUAL EQUIP'])]\n",
        "MT_data['ACTUAL EQUIP'] = MT_data['ACTUAL EQUIP'].str.split('.').str[-1]\n",
        "\n",
        "        \n",
        "# Remove any nan cell in LINEHAUL COSTS\n",
        "MT_data = MT_data[pd.notnull(MT_data['LINEHAUL COSTS'])]\n",
        "\n",
        "# Remove any nan cell in FUEL COSTS\n",
        "MT_data = MT_data[pd.notnull(MT_data['FUEL COSTS'])]\n",
        "\n",
        "# Remove any nan cell in ACC. COSTS\n",
        "MT_data = MT_data[pd.notnull(MT_data['ACC. COSTS'])]\n",
        "\n",
        "# Remove any nan cell in total ACTUAL COST\n",
        "MT_data = MT_data[pd.notnull(MT_data['TOTAL ACTUAL COST'])]\n",
        "\n",
        "# Add a LINEHAUL UNIT COSTS to the dataframe\n",
        "MT_data['LINEHAUL UNIT COSTS'] = MT_data['LINEHAUL COSTS']/MT_data['DISTANCE']\n",
        "\n",
        "# Drop the row if na is found in the MT_data['DEST CITY']\n",
        "MT_data = MT_data[pd.notnull(MT_data['DEST CITY'])]\n",
        "\n",
        "# Only conisder shipment has dest zip code in USA and Canada\n",
        "# Drop the row if ns is found in the MT_data['ORIGIN STATE']\n",
        "MT_data = MT_data[pd.notnull(MT_data['DEST STATE'])]\n",
        "MT_data = MT_data.reset_index(drop=True)\n",
        "\n",
        "for i in range(len(MT_data)):\n",
        "    if MT_data.loc[i,'DEST STATE'] in State_list:\n",
        "        pass\n",
        "    else:\n",
        "        MT_data = MT_data.drop(i)\n",
        "        \n",
        "# Drop the row if na is found in the MT_data['DEST ZIP']\n",
        "MT_data = MT_data[pd.notnull(MT_data['DEST ZIP'])]\n",
        "MT_data = MT_data.reset_index(drop=True)\n",
        "# Change 4 digits zips to 5 digis\n",
        "for i in (range(len(MT_data['DEST ZIP']))):\n",
        "    zipCode = str(MT_data.loc[i,'DEST ZIP'])\n",
        "    if zipCode.isdigit():\n",
        "        if len(zipCode) < 5:\n",
        "            MT_data.loc[i,'DEST ZIP'] = \"0\" * (5 - len(zipCode)) + zipCode\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "# Clean the column of PU_APPT as a new column called File_paried_data\n",
        "MT_data['File_paried_data'] = pd.to_datetime(MT_data['PU_APPT'].str.split(' ').str[0], errors = 'coerce')\n",
        "MT_data['File_paried_data'] = MT_data['File_paried_data'].dt.strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "8U40RRTd64ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA_data Cleaning\n",
        "\n",
        "# Set ID_OR_OPTIONAL_FIELD as an objective column\n",
        "DAT_data['ID_OR_OPTIONAL_FIELD'] = DAT_data['ID_OR_OPTIONAL_FIELD'].astype(str)\n",
        "\n",
        "# Clean the column of File_data  and add year '2022' before the month\n",
        "DAT_data['File_data'] = DAT_data['SOURCE_FILE_NAME'].str.split(' ').str[-1]\n",
        "DAT_data['File_data'] = DAT_data['File_data'].str.split('.').str[0]\n",
        "DAT_data['File_data'] = '2022-' + DAT_data['File_data']\n",
        "DAT_data['File_data'] = pd.to_datetime(DAT_data['File_data'])\n",
        "\n",
        "# Remove columns have ALL na\n",
        "DAT_data = DAT_data.drop('NOTE',axis = 1)\n",
        "\n",
        "\n",
        "# Drop the row if na is found in the DAT_data['SPOT_AVG_LINEHAUL_RATE']\n",
        "DAT_data = DAT_data[pd.notnull(DAT_data['SPOT_AVG_LINEHAUL_RATE'])]\n",
        "\n",
        "# Drop the row if na is found in the DAT_data['SPOT_TIME_FRAME']\n",
        "DAT_data = DAT_data[pd.notnull(DAT_data['SPOT_TIME_FRAME'])]\n",
        "\n",
        "# Drop the row if na is found in the DAT_data['CONTRACT_AVG_LINEHAUL_RATE']\n",
        "DAT_data = DAT_data[pd.notnull(DAT_data['CONTRACT_AVG_LINEHAUL_RATE'])]\n",
        "\n",
        "# Drop the row if na is found in the DAT_data['CONTRACT_TIME_FRAME']\n",
        "DAT_data = DAT_data[pd.notnull(DAT_data['CONTRACT_TIME_FRAME'])]"
      ],
      "metadata": {
        "id": "zqJAokrd7A3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join two tables\n",
        "#Join the table by setting ID_OR_OPTIONAL_FIELD as the key\n",
        "merge_df = MT_data.merge(DAT_data, on = 'ID_OR_OPTIONAL_FIELD', how = 'left')"
      ],
      "metadata": {
        "id": "rccRldE17B7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "# 1. Remove if File_data is NA\n",
        "merge_df_remove_NA = merge_df\n",
        "merge_df_remove_NA = merge_df_remove_NA[pd.notnull(merge_df_remove_NA['File_data'])] \n",
        "merge_df_remove_NA = merge_df_remove_NA.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# 2. Only keeps row if File_paried_data is not larger than File_data\n",
        "#for i in range(len(merge_df)):\n",
        "#    if pd.to_datetime(merge_df.loc[i, 'File_paried_data']) <= pd.to_datetime(merge_df.loc[i, 'File_data']):\n",
        "#        merge_df = merge_df.drop(index=i)\n",
        "\n",
        "for i in range(len(merge_df_remove_NA)):\n",
        "    if pd.to_datetime(merge_df_remove_NA.loc[i, 'File_paried_data']) <= pd.to_datetime(merge_df_remove_NA.loc[i, 'File_data']):\n",
        "        merge_df_remove_NA = merge_df_remove_NA.drop(index=i)\n"
      ],
      "metadata": {
        "id": "TqBOU2Yp7L9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show all columns in the file\n",
        "pd.set_option('display.max_columns', None)\n",
        "merge_df_remove_NA.head()"
      ],
      "metadata": {
        "id": "iuu1m6WXEqXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review column name\n",
        "merge_df_remove_NA.columns"
      ],
      "metadata": {
        "id": "P2E61J7jaJt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Selected Input columns\n",
        "required_column = ['SHIPMENT ID', 'CUSTOMER', 'DISTANCE', 'CASES', 'WEIGHT', 'VOLUME',\n",
        "       'SOURCE LOCATION ID', 'ORIGIN NAME', 'ORIGIN CITY', 'ORIGIN STATE',\n",
        "       'ORIGIN ZIP', 'DEST LOCATION ID', 'CONSIGNEE NAME', 'DEST CITY',\n",
        "       'DEST STATE', 'DEST ZIP', 'ACTUAL CARRIER', 'ACTUAL MODE',\n",
        "       'ACTUAL EQUIP', 'LINEHAUL COSTS','TOTAL ACTUAL COST', 'PU_APPT','DL_APPT',\n",
        "       'LINEHAUL UNIT COSTS','PC_MILER_PRACTICAL_MILEAGE',\n",
        "       'SPOT_AVG_LINEHAUL_RATE', 'SPOT_LOW_LINEHAUL_RATE',\n",
        "       'SPOT_HIGH_LINEHAUL_RATE', 'SPOT_FUEL_SURCHARGE', 'SPOT_TIME_FRAME',\n",
        "       'SPOT_ORIGIN_GEO_EXPANSION', 'SPOT_DESTINATION_GEO_EXPANSION',\n",
        "       'SPOT_NUMBER_OF_COMPANIES', 'SPOT_NUMBER_OF_REPORTS',\n",
        "       'SPOT_LINEHAUL_RATE_STDDEV', 'SPOT_YOUR_OWN_AVG_LINEHAUL_RATE',\n",
        "       'SPOT_YOUR_OWN_NUMBER_OF_REPORTS', 'SPOT_ERROR',\n",
        "       'CONTRACT_AVG_LINEHAUL_RATE', 'CONTRACT_LOW_LINEHAUL_RATE',\n",
        "       'CONTRACT_HIGH_LINEHAUL_RATE', 'CONTRACT_FUEL_SURCHARGE',\n",
        "       'CONTRACT_AVG_ACCESSORIAL_EXCLUDES_FUEL', 'CONTRACT_TIME_FRAME',\n",
        "       'CONTRACT_ORIGIN_GEO_EXPANSION', 'CONTRACT_DESTINATION_GEO_EXPANSION',\n",
        "       'CONTRACT_NUMBER_OF_COMPANIES', 'CONTRACT_NUMBER_OF_REPORTS',\n",
        "       'CONTRACT_LINEHAUL_RATE_STDDEV', 'CONTRACT_YOUR_OWN_AVG_LINEHAUL_RATE',\n",
        "       'CONTRACT_YOUR_OWN_NUMBER_OF_REPORTS', 'CONTRACT_ERROR', 'ORIG_CITY',\n",
        "       'ORIG_STATE', 'ORIG_POSTAL_CODE', 'DEST_CITY', 'DEST_STATE',\n",
        "       'DEST_POSTAL_CODE', 'TRUCK_TYPE', 'RUN_ID', 'SOURCE_FILE_NAME']\n",
        "cleaned_df = merge_df_remove_NA[required_column]"
      ],
      "metadata": {
        "id": "ShCLwhO9HlQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.head()"
      ],
      "metadata": {
        "id": "VDTodGEbZrXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create 3 seperate sample datasets for TL, LTL, and railway"
      ],
      "metadata": {
        "id": "XzA7D6cQ3bn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LTL_Cleaned_Data = cleaned_df[cleaned_df['ACTUAL MODE'] == 'LTL']\n",
        "TL_Cleaned_Data = cleaned_df[cleaned_df['ACTUAL MODE'] == 'TL']\n",
        "INTERMODAL_Cleaned_Data = cleaned_df[cleaned_df['ACTUAL MODE'] == 'INTERMODAL']"
      ],
      "metadata": {
        "id": "JKhBHgVn3Xy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Dataset"
      ],
      "metadata": {
        "id": "qvrvYkWok9ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Output_path = \"/content/gdrive/MyDrive/ML-Transportation-Rate/sample data\"\n",
        "cleaned_df.to_csv( Output_path +'/Overall_Sample_Data.csv')\n",
        "LTL_Cleaned_Data.to_csv( Output_path +'/LTL_Cleaned_Sample_Data.csv')\n",
        "TL_Cleaned_Data.to_csv( Output_path +'/TL_Cleaned_Sample_Data.csv')\n",
        "INTERMODAL_Cleaned_Data.to_csv( Output_path +'/INTERMODAL_Cleaned_Sample_Data.csv')"
      ],
      "metadata": {
        "id": "2eQf63BqaWTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mr-tgBDY6MuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}